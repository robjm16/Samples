{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "This notebook demonstrates sentiment analysis and topic modeling on a selection of tweets from Twitter. The tweets were pulled on October 16, 2017, via the Twitter API, using the search term \"Tesla\" (the car company).  The tweets were tokenized, evaluated for positive/negative sentiment and broken down by topics and further analyzed (e.g., for hashtags).   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict, Counter \n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect tweets and store them in a dataframe "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to add in personal token/keys/secrets\n",
    "access_token = 'ACCESS TOKEN'\n",
    "access_token_secret = 'ACCESS TOKEN SECRET'\n",
    "consumer_key = 'CONSUMER KEY'\n",
    "consumer_secret = 'CONSUMER SECRET'\n",
    "\n",
    "auth = tweepy.OAuthHandler(consumer_key, consumer_secret)\n",
    "auth.set_access_token(access_token, access_token_secret)\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_tweets(api, input_query):\n",
    "    for tweet in tweepy.Cursor(api.search, q=input_query, lang=\"en\").items():\n",
    "        yield tweet\n",
    "\n",
    "input_queries = ['Tesla']\n",
    "tweets = {}\n",
    "for input_query in input_queries:\n",
    "    tweets[input_query] = get_tweets(api, input_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla\n"
     ]
    }
   ],
   "source": [
    "dataset = defaultdict(list)\n",
    "download_tweet_count = 1500\n",
    "for input_query in input_queries:\n",
    "    print(input_query)\n",
    "    counter = 0\n",
    "    while counter < download_tweet_count:\n",
    "        try:\n",
    "            tweet = next(tweets[input_query])\n",
    "            dataset['topic'].append(input_query)\n",
    "            dataset['id'].append(tweet.id)\n",
    "            # user related information\n",
    "            dataset['username'].append(tweet.author.screen_name)\n",
    "            dataset['name'].append(tweet.author.name)\n",
    "            dataset['user_followers_count'].append(tweet.author.followers_count)\n",
    "            dataset['user_friends_count'].append(tweet.author.friends_count)\n",
    "            # tweet related information\n",
    "            dataset['text'].append(tweet.text)\n",
    "            dataset['created_at'].append(tweet.created_at.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "            dataset['favorite_count'].append(tweet.favorite_count)\n",
    "            dataset['retweet_count'].append(tweet.retweet_count)\n",
    "            # some extracted data from tweet\n",
    "            dataset['hashtags'].append(\n",
    "                ','.join([ht['text'] \n",
    "                          for ht in tweet.entities['hashtags']]))\n",
    "            dataset['mentioned_urls'].append(\n",
    "                ','.join([url['url'] \n",
    "                          for url in tweet.entities['urls']]))\n",
    "            dataset['mentioned_user_ids'].append(\n",
    "                ','.join([mention['id_str'] \n",
    "                          for mention in tweet.entities['user_mentions']]))\n",
    "            dataset['mentioned_user_names'].append(\n",
    "                ','.join([mention['screen_name'] \n",
    "                          for mention in tweet.entities['user_mentions']]))\n",
    "            counter +=1\n",
    "            if counter == download_tweet_count:\n",
    "                break\n",
    "        except:\n",
    "            print(len(dataset['id']))\n",
    "            print('Sleeping for 15 minutes')\n",
    "            time.sleep(15*60) # sleep for 15 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>username</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-16 23:54:32</td>\n",
       "      <td>This F-350 might as well be a tv show — oh for...</td>\n",
       "      <td></td>\n",
       "      <td>tesla_ebooks</td>\n",
       "      <td>67</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-16 23:54:31</td>\n",
       "      <td>Tesla unveils a brand new dual-charging port f...</td>\n",
       "      <td></td>\n",
       "      <td>uohanalilly</td>\n",
       "      <td>9116</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-16 23:54:27</td>\n",
       "      <td>RT @Forbes: 4 takeaways from Tesla firing hund...</td>\n",
       "      <td></td>\n",
       "      <td>LB_Hudson</td>\n",
       "      <td>648</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-16 23:54:26</td>\n",
       "      <td>@pcanella It’s so obvious haha. Like today I w...</td>\n",
       "      <td></td>\n",
       "      <td>toddbodene</td>\n",
       "      <td>550</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-16 23:54:18</td>\n",
       "      <td>#pinkpelicanshoutout to @Team5937 Renaissance ...</td>\n",
       "      <td>pinkpelicanshoutout</td>\n",
       "      <td>PinkPelicansFTC</td>\n",
       "      <td>138</td>\n",
       "      <td>Tesla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at                                               text  \\\n",
       "0  2017-10-16 23:54:32  This F-350 might as well be a tv show — oh for...   \n",
       "1  2017-10-16 23:54:31  Tesla unveils a brand new dual-charging port f...   \n",
       "2  2017-10-16 23:54:27  RT @Forbes: 4 takeaways from Tesla firing hund...   \n",
       "3  2017-10-16 23:54:26  @pcanella It’s so obvious haha. Like today I w...   \n",
       "4  2017-10-16 23:54:18  #pinkpelicanshoutout to @Team5937 Renaissance ...   \n",
       "\n",
       "              hashtags         username  user_followers_count  topic  \n",
       "0                          tesla_ebooks                    67  Tesla  \n",
       "1                           uohanalilly                  9116  Tesla  \n",
       "2                             LB_Hudson                   648  Tesla  \n",
       "3                            toddbodene                   550  Tesla  \n",
       "4  pinkpelicanshoutout  PinkPelicansFTC                   138  Tesla  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Put in dataframe and view selected rows/columns \n",
    "df_Tesla = pd.DataFrame.from_dict(dataset)\n",
    "df_Tesla[['created_at','text','hashtags','username','user_followers_count','topic']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Initial Sentiment Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05881499999999996"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vader Compound scores by tweet text \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_compound = []\n",
    "for i in df_Tesla.text : \n",
    "    ss=sid.polarity_scores(i)['compound']\n",
    "    vader_compound.append(ss)\n",
    "df_Tesla['Vader_Compound']=vader_compound \n",
    "vader_compound_average = df_Tesla['Vader_Compound'].mean()\n",
    "vader_compound_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.04759"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vader Negative scores by tweet text \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_neg = []\n",
    "for i in df_Tesla.text : \n",
    "    ss=sid.polarity_scores(i)['neg']\n",
    "    vader_neg.append(ss)\n",
    "df_Tesla['Vader_Negative']=vader_neg \n",
    "vader_neg_average = df_Tesla['Vader_Negative'].mean()\n",
    "vader_neg_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8825553333333345"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vader Neutral scores by tweet text \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_neu = []\n",
    "for i in df_Tesla.text: \n",
    "    ss=sid.polarity_scores(i)['neu']\n",
    "    vader_neu.append(ss)\n",
    "df_Tesla['Vader_Neutral']=vader_neu \n",
    "vader_neutral_average = df_Tesla['Vader_Neutral'].mean()\n",
    "vader_neutral_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06985066666666667"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vader Positive scores by tweet text \n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_pos = []\n",
    "for i in df_Tesla.text : \n",
    "    ss=sid.polarity_scores(i)['pos']\n",
    "    vader_pos.append(ss)\n",
    "df_Tesla['Vader_Positive']=vader_pos\n",
    "vader_positive_average = df_Tesla['Vader_Positive'].mean()\n",
    "vader_positive_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader averages for Tesla Oct 16 tweets: \n",
      "Vader compound: 0.05881499999999996\n",
      "Vader negative: 0.04759\n",
      "Vader neutral:  0.8825553333333345\n",
      "Vader positive: 0.06985066666666667\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Vader averages for Tesla Oct 16 tweets: ' + '\\n' \n",
    "      'Vader compound: ' + str(vader_compound_average) + '\\n'\n",
    "      'Vader negative: ' + str(vader_neg_average) + '\\n'\n",
    "      'Vader neutral:  ' + str(vader_neutral_average) + '\\n'\n",
    "      'Vader positive: ' + str(vader_positive_average) + '\\n')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on analysis of raw text, Tesla's tweets are mostly neutral in tone, with slightly more positive than negative sentiments expressed.  The tweets were pulled at a time when Tesla was in the news for employee layoffs and production delays as well as for an effort to help Puerto Rico recover from Hurricane Maria by shipping its Powerpacks to hospitals and other critical facilities. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @Forbes: 4 takeaways from Tesla firing hundreds of people: https://t.co/HwarKVcEEJ https://t.co/ZlcuJBHpfx\n"
     ]
    }
   ],
   "source": [
    "# Tokenize the text \n",
    "all_tweets = df_Tesla['text'].values\n",
    "print(all_tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['rt', 'forbes', '4', 'takeaways', 'from', 'tesla', 'firing', 'hundreds', 'of', 'people', 'httpstcohwarkvceej', 'httpstcozlcujbhpfx']\n"
     ]
    }
   ],
   "source": [
    "# Text tokenization\n",
    "import string\n",
    "exclude = set(string.punctuation)\n",
    "tokenized_all_tweets = []\n",
    "tokenizer = TweetTokenizer()\n",
    "for tweet in all_tweets :\n",
    "    tokens = tokenizer.tokenize(tweet.lower())\n",
    "    tokenized_all_tweets.append(''.join([ch for ch in ' '.join(tokens) if ch not in exclude]).split())\n",
    "print(tokenized_all_tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forbes', '4', 'takeaways', 'tesla', 'firing', 'hundreds', 'people', 'httpstcohwarkvceej', 'httpstcozlcujbhpfx']\n"
     ]
    }
   ],
   "source": [
    "# Stop-word removal \n",
    "sws = set(stopwords.words('english')+ ['rt', u'\\u2026', u'\\u2019' ]) # Added tweet-specific terms for removal \n",
    "sws_removed_all_tweets = []\n",
    "for j,sent in enumerate(tokenized_all_tweets):\n",
    "    sws_removed_all_tweets.append([i for i in sent if i not in sws])\n",
    "print(sws_removed_all_tweets[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forb', '4', 'takeaway', 'tesla', 'fire', 'hundr', 'peopl', 'httpstcohwarkvceej', 'httpstcozlcujbhpfx']\n"
     ]
    }
   ],
   "source": [
    "# Word stemming\n",
    "from nltk.stem.porter import *\n",
    "stemmer = PorterStemmer()\n",
    "stemmed = []\n",
    "for j,sent in enumerate(sws_removed_all_tweets) :\n",
    "    stemmed.append([stemmer.stem(i) for i in sent])\n",
    "print(stemmed[2])    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>mentioned_urls</th>\n",
       "      <th>mentioned_user_ids</th>\n",
       "      <th>mentioned_user_names</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>username</th>\n",
       "      <th>Vader_Compound</th>\n",
       "      <th>Vader_Negative</th>\n",
       "      <th>Vader_Neutral</th>\n",
       "      <th>Vader_Positive</th>\n",
       "      <th>tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-16 23:54:32</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075519177121792</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>alseT</td>\n",
       "      <td>0</td>\n",
       "      <td>This F-350 might as well be a tv show — oh for...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>tesla_ebooks</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.116</td>\n",
       "      <td>[f, 350, might, well, tv, show, —, oh, forev, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-16 23:54:31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075513309335553</td>\n",
       "      <td>https://t.co/XxAk0viIQW</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Uzzi Ohana</td>\n",
       "      <td>0</td>\n",
       "      <td>Tesla unveils a brand new dual-charging port f...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>9116</td>\n",
       "      <td>7114</td>\n",
       "      <td>uohanalilly</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[tesla, unveil, brand, new, dualcharg, port, c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at  favorite_count hashtags                  id  \\\n",
       "0  2017-10-16 23:54:32               0           920075519177121792   \n",
       "1  2017-10-16 23:54:31               0           920075513309335553   \n",
       "\n",
       "            mentioned_urls mentioned_user_ids mentioned_user_names  \\\n",
       "0                                                                    \n",
       "1  https://t.co/XxAk0viIQW                                           \n",
       "\n",
       "         name  retweet_count  \\\n",
       "0       alseT              0   \n",
       "1  Uzzi Ohana              0   \n",
       "\n",
       "                                                text  topic  \\\n",
       "0  This F-350 might as well be a tv show — oh for...  Tesla   \n",
       "1  Tesla unveils a brand new dual-charging port f...  Tesla   \n",
       "\n",
       "   user_followers_count  user_friends_count      username  Vader_Compound  \\\n",
       "0                    67                  10  tesla_ebooks          0.2732   \n",
       "1                  9116                7114   uohanalilly          0.0000   \n",
       "\n",
       "   Vader_Negative  Vader_Neutral  Vader_Positive  \\\n",
       "0             0.0          0.884           0.116   \n",
       "1             0.0          1.000           0.000   \n",
       "\n",
       "                                              tokens  \n",
       "0  [f, 350, might, well, tv, show, —, oh, forev, ...  \n",
       "1  [tesla, unveil, brand, new, dualcharg, port, c...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Attach tokens to the dataframe \n",
    "df_Tesla['tokens'] =stemmed\n",
    "df_Tesla.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic Modeling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gensim Library\n",
    "from gensim import corpora, models\n",
    "dictionary = corpora.Dictionary(sws_removed_all_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Next, our dictionary must be converted into a bag-of-words:\n",
    "corpus_Tesla = [dictionary.doc2bow(text) for text in sws_removed_all_tweets]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(14, 1), (23, 1), (24, 1), (25, 1), (26, 1), (27, 1), (28, 1), (29, 1), (30, 1)]\n"
     ]
    }
   ],
   "source": [
    "print(corpus_Tesla[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LDA Model \n",
    "ldamodel_Tesla= models.ldamodel.LdaModel(corpus_Tesla, num_topics=3, id2word = dictionary, passes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0,\n",
       "  '0.072*\"tesla\" + 0.047*\"puerto\" + 0.045*\"rico\" + 0.032*\"powerpacks\" + 0.027*\"reportedly\" + 0.023*\"shipped\" + 0.008*\"trump\"'),\n",
       " (1,\n",
       "  '0.049*\"tesla\" + 0.011*\"car\" + 0.011*\"time\" + 0.010*\"company\" + 0.010*\"work\" + 0.010*\"technology\" + 0.009*\"nothing\"'),\n",
       " (2,\n",
       "  '0.069*\"tesla\" + 0.016*\"hundreds\" + 0.009*\"model\" + 0.009*\"workers\" + 0.007*\"people\" + 0.006*\"solar\" + 0.006*\"city\"')]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel_Tesla.print_topics(num_topics=3, num_words=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0, 0.76020290426846937),\n",
       "  (1, 0.21669543729371346),\n",
       "  (2, 0.023101658437817273)],\n",
       " [(0, 0.035495829775179739),\n",
       "  (1, 0.036484506967565257),\n",
       "  (2, 0.92801966325725493)],\n",
       " [(0, 0.033880882928287989),\n",
       "  (1, 0.033757698872328205),\n",
       "  (2, 0.93236141819938378)],\n",
       " [(0, 0.95131256434257139),\n",
       "  (1, 0.023342839698279796),\n",
       "  (2, 0.025344595959148775)],\n",
       " [(0, 0.024284461334445454),\n",
       "  (1, 0.95143490815363896),\n",
       "  (2, 0.024280630511915702)]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determining the primary topic for each tweet \n",
    "topic_ratings_Tesla_tweets = []\n",
    "for i in range(len(corpus_Tesla)) :\n",
    "    ratings = ldamodel_Tesla.get_document_topics(corpus_Tesla[i])\n",
    "    topic_ratings_Tesla_tweets.append(ratings)\n",
    "topic_ratings_Tesla_tweets[0:5] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 2, 2, 0, 1]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "topic_codes_Tesla_tweets = []\n",
    "\n",
    "for i in topic_ratings_Tesla_tweets :\n",
    "   code = max(i, key=itemgetter(1))[0]\n",
    "   topic_codes_Tesla_tweets.append(code)\n",
    "\n",
    "topic_codes_Tesla_tweets[:5]  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>created_at</th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>id</th>\n",
       "      <th>mentioned_urls</th>\n",
       "      <th>mentioned_user_ids</th>\n",
       "      <th>mentioned_user_names</th>\n",
       "      <th>name</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>text</th>\n",
       "      <th>topic</th>\n",
       "      <th>user_followers_count</th>\n",
       "      <th>user_friends_count</th>\n",
       "      <th>username</th>\n",
       "      <th>Vader_Compound</th>\n",
       "      <th>Vader_Negative</th>\n",
       "      <th>Vader_Neutral</th>\n",
       "      <th>Vader_Positive</th>\n",
       "      <th>tokens</th>\n",
       "      <th>topic_codes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-10-16 23:54:32</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075519177121792</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>alseT</td>\n",
       "      <td>0</td>\n",
       "      <td>This F-350 might as well be a tv show — oh for...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>67</td>\n",
       "      <td>10</td>\n",
       "      <td>tesla_ebooks</td>\n",
       "      <td>0.2732</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.116</td>\n",
       "      <td>[f, 350, might, well, tv, show, —, oh, forev, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017-10-16 23:54:31</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075513309335553</td>\n",
       "      <td>https://t.co/XxAk0viIQW</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>Uzzi Ohana</td>\n",
       "      <td>0</td>\n",
       "      <td>Tesla unveils a brand new dual-charging port f...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>9116</td>\n",
       "      <td>7114</td>\n",
       "      <td>uohanalilly</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[tesla, unveil, brand, new, dualcharg, port, c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017-10-16 23:54:27</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075497945686016</td>\n",
       "      <td>https://t.co/HwarKVcEEJ</td>\n",
       "      <td>91478624</td>\n",
       "      <td>Forbes</td>\n",
       "      <td>L.B. Hudson</td>\n",
       "      <td>19</td>\n",
       "      <td>RT @Forbes: 4 takeaways from Tesla firing hund...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>648</td>\n",
       "      <td>361</td>\n",
       "      <td>LB_Hudson</td>\n",
       "      <td>-0.3400</td>\n",
       "      <td>0.194</td>\n",
       "      <td>0.806</td>\n",
       "      <td>0.000</td>\n",
       "      <td>[forb, 4, takeaway, tesla, fire, hundr, peopl,...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017-10-16 23:54:26</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>920075493059072001</td>\n",
       "      <td></td>\n",
       "      <td>8685732</td>\n",
       "      <td>pcanella</td>\n",
       "      <td>Todd Bodene</td>\n",
       "      <td>0</td>\n",
       "      <td>@pcanella It’s so obvious haha. Like today I w...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>550</td>\n",
       "      <td>738</td>\n",
       "      <td>toddbodene</td>\n",
       "      <td>0.7220</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.792</td>\n",
       "      <td>0.208</td>\n",
       "      <td>[pcanella, obviou, haha, like, today, follow, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-10-16 23:54:18</td>\n",
       "      <td>0</td>\n",
       "      <td>pinkpelicanshoutout</td>\n",
       "      <td>920075460389801984</td>\n",
       "      <td>https://t.co/DafTRy34qL</td>\n",
       "      <td>2170839804</td>\n",
       "      <td>Team5937</td>\n",
       "      <td>PinkPelicanRobotics</td>\n",
       "      <td>0</td>\n",
       "      <td>#pinkpelicanshoutout to @Team5937 Renaissance ...</td>\n",
       "      <td>Tesla</td>\n",
       "      <td>138</td>\n",
       "      <td>230</td>\n",
       "      <td>PinkPelicansFTC</td>\n",
       "      <td>0.5229</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.816</td>\n",
       "      <td>0.184</td>\n",
       "      <td>[pinkpelicanshoutout, team5937, renaiss, robot...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            created_at  favorite_count             hashtags  \\\n",
       "0  2017-10-16 23:54:32               0                        \n",
       "1  2017-10-16 23:54:31               0                        \n",
       "2  2017-10-16 23:54:27               0                        \n",
       "3  2017-10-16 23:54:26               0                        \n",
       "4  2017-10-16 23:54:18               0  pinkpelicanshoutout   \n",
       "\n",
       "                   id           mentioned_urls mentioned_user_ids  \\\n",
       "0  920075519177121792                                               \n",
       "1  920075513309335553  https://t.co/XxAk0viIQW                      \n",
       "2  920075497945686016  https://t.co/HwarKVcEEJ           91478624   \n",
       "3  920075493059072001                                     8685732   \n",
       "4  920075460389801984  https://t.co/DafTRy34qL         2170839804   \n",
       "\n",
       "  mentioned_user_names                 name  retweet_count  \\\n",
       "0                                     alseT              0   \n",
       "1                                Uzzi Ohana              0   \n",
       "2               Forbes          L.B. Hudson             19   \n",
       "3             pcanella          Todd Bodene              0   \n",
       "4             Team5937  PinkPelicanRobotics              0   \n",
       "\n",
       "                                                text  topic  \\\n",
       "0  This F-350 might as well be a tv show — oh for...  Tesla   \n",
       "1  Tesla unveils a brand new dual-charging port f...  Tesla   \n",
       "2  RT @Forbes: 4 takeaways from Tesla firing hund...  Tesla   \n",
       "3  @pcanella It’s so obvious haha. Like today I w...  Tesla   \n",
       "4  #pinkpelicanshoutout to @Team5937 Renaissance ...  Tesla   \n",
       "\n",
       "   user_followers_count  user_friends_count         username  Vader_Compound  \\\n",
       "0                    67                  10     tesla_ebooks          0.2732   \n",
       "1                  9116                7114      uohanalilly          0.0000   \n",
       "2                   648                 361        LB_Hudson         -0.3400   \n",
       "3                   550                 738       toddbodene          0.7220   \n",
       "4                   138                 230  PinkPelicansFTC          0.5229   \n",
       "\n",
       "   Vader_Negative  Vader_Neutral  Vader_Positive  \\\n",
       "0           0.000          0.884           0.116   \n",
       "1           0.000          1.000           0.000   \n",
       "2           0.194          0.806           0.000   \n",
       "3           0.000          0.792           0.208   \n",
       "4           0.000          0.816           0.184   \n",
       "\n",
       "                                              tokens  topic_codes  \n",
       "0  [f, 350, might, well, tv, show, —, oh, forev, ...            0  \n",
       "1  [tesla, unveil, brand, new, dualcharg, port, c...            2  \n",
       "2  [forb, 4, takeaway, tesla, fire, hundr, peopl,...            2  \n",
       "3  [pcanella, obviou, haha, like, today, follow, ...            0  \n",
       "4  [pinkpelicanshoutout, team5937, renaiss, robot...            1  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Append topic codes to dataframe \n",
    "df_Tesla['topic_codes']=topic_codes_Tesla_tweets\n",
    "df_Tesla.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader compound score for Topic 1: 0.0272567692308\n",
      "\n",
      "Topic words : 0.072*\"tesla\" + 0.047*\"puerto\" + 0.045*\"rico\" + 0.032*\"powerpacks\" + 0.027*\"reportedly\" + 0.023*\"shipped\" + 0.008*\"trump\" + 0.008*\"elon\" + 0.007*\"donald\" + 0.007*\"shipping\"\n"
     ]
    }
   ],
   "source": [
    "# Vader Compound scores by tweet text by topic\n",
    "df1 = df_Tesla.loc[df_Tesla['topic_codes'] == 0]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_totals = []\n",
    "for i in df1.text : \n",
    "    ss=sid.polarity_scores(i)['compound']\n",
    "    vader_totals.append(ss)\n",
    "vader_compound = np.array(vader_totals)\n",
    "print('Vader compound score for Topic 1: ' + str(vader_compound.mean()) + '\\n')\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(0)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader compound score for Topic 2: 0.209445757576\n",
      "\n",
      "Topic words : 0.049*\"tesla\" + 0.011*\"car\" + 0.011*\"time\" + 0.010*\"company\" + 0.010*\"work\" + 0.010*\"technology\" + 0.009*\"nothing\" + 0.009*\"waste\" + 0.009*\"hard\" + 0.009*\"marvel\"\n"
     ]
    }
   ],
   "source": [
    "df2 = df_Tesla.loc[df_Tesla['topic_codes'] == 1]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_totals = []\n",
    "for i in df2.text : \n",
    "    ss=sid.polarity_scores(i)['compound']\n",
    "    vader_totals.append(ss)\n",
    "vader_compound = np.array(vader_totals)\n",
    "print('Vader compound score for Topic 2: ' + str(vader_compound.mean()) + '\\n')\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vader compound score for Topic 3: 0.00267019230769\n",
      "\n",
      "Topic words : 0.069*\"tesla\" + 0.016*\"hundreds\" + 0.009*\"model\" + 0.009*\"workers\" + 0.007*\"people\" + 0.006*\"solar\" + 0.006*\"city\" + 0.005*\"firing\" + 0.005*\"employees\" + 0.005*\"spacex\"\n"
     ]
    }
   ],
   "source": [
    "df3 = df_Tesla.loc[df_Tesla['topic_codes'] == 2]\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "vader_totals = []\n",
    "for i in df3.text : \n",
    "    ss=sid.polarity_scores(i)['compound']\n",
    "    vader_totals.append(ss)\n",
    "vader_compound = np.array(vader_totals)\n",
    "print('Vader compound score for Topic 3: ' + str(vader_compound.mean()) + '\\n')\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(2)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not surprisingly, the third topic, which captures the employee layoffs, had the lowest sentiment score.  The first topic, capturing the sending of Powerpacks to Puerto Rico, was more positive. The second topic, which seems to capture Tesla's general innovation, yielded the highest sentiment score.  See below for the most commom hashtags by topic, which adds further context to the above.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Count most common hastags by topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags in Topic 1: \n",
      "Topic words : 0.072*\"tesla\" + 0.047*\"puerto\" + 0.045*\"rico\" + 0.032*\"powerpacks\" + 0.027*\"reportedly\" + 0.023*\"shipped\" + 0.008*\"trump\" + 0.008*\"elon\" + 0.007*\"donald\" + 0.007*\"shipping\"\n",
      "============================================================\n",
      "             Count\n",
      "Hashtag           \n",
      "Tesla           41\n",
      "tesla            8\n",
      "business         5\n",
      "ElonMusk         5\n",
      "PuertoRico       5\n",
      "science          4\n",
      "powerwall        4\n",
      "feedly           4\n",
      "TeslaModel3      4\n",
      "Model3           4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "for i in df1.hashtags :\n",
    "    tokens = nltk.word_tokenize(i) \n",
    "    hashtags.extend(tokens)\n",
    "hashtags = [hashtag for hashtag in hashtags if hashtag != \",\"]\n",
    "most_common_hashtags = Counter(hashtags).most_common(10)\n",
    "\n",
    "print (\"Top 10 Hashtags in Topic 1: \")\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(0)) \n",
    "\n",
    "print ('='* 60)\n",
    "rslt = pd.DataFrame(most_common_hashtags, columns=['Hashtag', 'Count']).set_index('Hashtag')\n",
    "print(rslt)\n",
    "print ('='* 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags in Topic 2: \n",
      "Topic words : 0.049*\"tesla\" + 0.011*\"car\" + 0.011*\"time\" + 0.010*\"company\" + 0.010*\"work\" + 0.010*\"technology\" + 0.009*\"nothing\" + 0.009*\"waste\" + 0.009*\"hard\" + 0.009*\"marvel\"\n",
      "============================================================\n",
      "             Count\n",
      "Hashtag           \n",
      "Tesla           14\n",
      "ElectricGT       3\n",
      "TeslaModelS      3\n",
      "techAU           3\n",
      "motorsport       3\n",
      "lawyer           3\n",
      "legaljobs        3\n",
      "teslamodels      3\n",
      "debate           3\n",
      "Dominica         2\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "for i in df2.hashtags :\n",
    "    tokens = nltk.word_tokenize(i) \n",
    "    hashtags.extend(tokens)\n",
    "hashtags = [hashtag for hashtag in hashtags if hashtag != \",\"]\n",
    "most_common_hashtags = Counter(hashtags).most_common(10)\n",
    "\n",
    "print (\"Top 10 Hashtags in Topic 2: \")\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(1)) \n",
    "\n",
    "print ('='* 60)\n",
    "rslt = pd.DataFrame(most_common_hashtags, columns=['Hashtag', 'Count']).set_index('Hashtag')\n",
    "print(rslt)\n",
    "print ('='* 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Hashtags in Topic 3: \n",
      "Topic words : 0.069*\"tesla\" + 0.016*\"hundreds\" + 0.009*\"model\" + 0.009*\"workers\" + 0.007*\"people\" + 0.006*\"solar\" + 0.006*\"city\" + 0.005*\"firing\" + 0.005*\"employees\" + 0.005*\"spacex\"\n",
      "============================================================\n",
      "             Count\n",
      "Hashtag           \n",
      "Tesla           45\n",
      "Model3           8\n",
      "model3           8\n",
      "tesla            7\n",
      "smallcap         7\n",
      "tech             5\n",
      "electriccar      4\n",
      "China            4\n",
      "AI               4\n",
      "PuertoRico       4\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "hashtags = []\n",
    "for i in df3.hashtags :\n",
    "    tokens = nltk.word_tokenize(i) \n",
    "    hashtags.extend(tokens)\n",
    "hashtags = [hashtag for hashtag in hashtags if hashtag != \",\"]\n",
    "most_common_hashtags = Counter(hashtags).most_common(10)\n",
    "\n",
    "print (\"Top 10 Hashtags in Topic 3: \")\n",
    "print('Topic words :', ldamodel_Tesla.print_topic(2)) \n",
    "\n",
    "print ('='* 60)\n",
    "rslt = pd.DataFrame(most_common_hashtags, columns=['Hashtag', 'Count']).set_index('Hashtag')\n",
    "print(rslt)\n",
    "print ('='* 60)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
